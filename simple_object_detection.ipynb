{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1920435a",
   "metadata": {},
   "source": [
    "# Simple Object Detection in Tensorflow\n",
    "\n",
    "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
    "\n",
    "* explore the Tensorflow Hub for object detection models\n",
    "* load the models in your workspace\n",
    "* preprocess an image for inference \n",
    "* run inference on the models and inspect the output\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30194080",
   "metadata": {},
   "source": [
    "<h3>Imports </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ce20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80315686",
   "metadata": {},
   "source": [
    "### Download the model from Tensorflow Hub\n",
    "\n",
    "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects. \n",
    "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories. \n",
    "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection). \n",
    "- You can select a model to see more information about it and copy the URL so you can download it to your workspace. \n",
    "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
    "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f2c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can switch the commented lines here to pick the other model\n",
    "\n",
    "# inception resnet version 2\n",
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "\n",
    "# You can choose ssd mobilenet version 2 instead and compare the results\n",
    "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfc0d9",
   "metadata": {},
   "source": [
    "#### Load the model\n",
    "\n",
    "Next, you'll load the model specified by the `module_handle`.\n",
    "- This will take a few minutes to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5086ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = hub.load(module_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c419e8",
   "metadata": {},
   "source": [
    "#### Choose the default signature\n",
    "\n",
    "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model. \n",
    "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dcc89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x1E48823B940>}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the available signatures for this particular model\n",
    "model.signatures.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966129c",
   "metadata": {},
   "source": [
    "Please choose the 'default' signature for your object detector.\n",
    "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae7c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = model.signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0405af3",
   "metadata": {},
   "source": [
    "### download_and_resize_image\n",
    "\n",
    "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7dfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_resize_image(url, new_width=256, new_height=256):\n",
    "    '''\n",
    "    Fetches an image online, resizes it and saves it locally.\n",
    "    \n",
    "    Args:\n",
    "        url (string) -- link to the image\n",
    "        new_width (int) -- size in pixels used for resizing the width of the image\n",
    "        new_height (int) -- size in pixels used for resizing the length of the image\n",
    "        \n",
    "    Returns:\n",
    "        (string) -- path to the saved image\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # create a temporary file ending with \".jpg\"\n",
    "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "    \n",
    "    # opens the given URL\n",
    "    response = urlopen(url)\n",
    "    \n",
    "    # reads the image fetched from the URL\n",
    "    image_data = response.read()\n",
    "    \n",
    "    # puts the image data in memory buffer\n",
    "    image_data = BytesIO(image_data)\n",
    "    \n",
    "    # opens the image\n",
    "    pil_image = Image.open(image_data)\n",
    "    \n",
    "    # resizes the image. will crop if aspect ratio is different.\n",
    "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "    \n",
    "    # converts to the RGB colorspace\n",
    "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "    \n",
    "    # saves the image to the temporary file created earlier\n",
    "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "    \n",
    "    print(\"Image downloaded to %s.\" % filename)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95382eac",
   "metadata": {},
   "source": [
    "### Download and preprocess an image\n",
    "\n",
    "Now, using `download_and_resize_image` you can get a sample image online and save it locally. \n",
    "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
    "- You can use the original width and height of the image but feel free to modify it and see what results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c39e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded to C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpd4dgnl65.jpg.\n"
     ]
    }
   ],
   "source": [
    "# You can choose a different URL that points to an image of your choice\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
    "\n",
    "# download the image and use the original height and width\n",
    "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d6c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    '''\n",
    "    Loads a JPEG image and converts it to a tensor.\n",
    "    \n",
    "    Args:\n",
    "        path (string) -- path to a locally saved JPEG image\n",
    "    \n",
    "    Returns:\n",
    "        (tensor) -- an image tensor\n",
    "    '''\n",
    "    \n",
    "    # read the file\n",
    "    img = tf.io.read_file(path)\n",
    "    \n",
    "    # convert to a tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def run_detector(detector, path):\n",
    "    '''\n",
    "    Runs inference on a local file using an object detection model.\n",
    "    \n",
    "    Args:\n",
    "        detector (model) -- an object detection model loaded from TF Hub\n",
    "        path (string) -- path to an image saved locally\n",
    "    '''\n",
    "    \n",
    "    # load an image tensor from a local file path\n",
    "    img = load_img(path)\n",
    "\n",
    "    # add a batch dimension in front of the tensor\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    \n",
    "    # run inference using the model\n",
    "    result = detector(converted_img)\n",
    "\n",
    "    # save the results in a dictionary\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "    # print results\n",
    "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "\n",
    "    print(result[\"detection_scores\"])\n",
    "    print(result[\"detection_class_entities\"])\n",
    "    print(result[\"detection_boxes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f23f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.6544854  0.6114538  0.6042279  0.5926324  0.5921865  0.5804909\n",
      " 0.551406   0.49466902 0.47515693 0.47342172 0.4399601  0.41485146\n",
      " 0.40629667 0.39828917 0.39765266 0.3762097  0.37279388 0.36574712\n",
      " 0.3526072  0.33274654 0.30428746 0.2727655  0.26864904 0.25777102\n",
      " 0.25290623 0.24612118 0.23403832 0.20342913 0.182294   0.18045734\n",
      " 0.17571318 0.16435105 0.15849939 0.15666042 0.15470882 0.15452766\n",
      " 0.14924937 0.13340624 0.12948255 0.12649707 0.12044212 0.11767316\n",
      " 0.11356076 0.11114731 0.1110027  0.10914937 0.10604054 0.08940534\n",
      " 0.08598262 0.08280214 0.08104537 0.07806072 0.0776033  0.07628618\n",
      " 0.07546869 0.07444122 0.07427177 0.07204835 0.07177533 0.07102209\n",
      " 0.07032692 0.06809694 0.06304515 0.06285925 0.06270927 0.06223953\n",
      " 0.05882128 0.05815051 0.05795779 0.05787583 0.05462363 0.05274331\n",
      " 0.05133716 0.04826545 0.04708425 0.04682917 0.04495221 0.04405148\n",
      " 0.04360704 0.0411347  0.04109954 0.03968582 0.03934995 0.03912798\n",
      " 0.03879518 0.03878601 0.03739646 0.03606934 0.03367105 0.0336685\n",
      " 0.032602   0.03253522 0.03201505 0.02983091 0.02877986 0.02867631\n",
      " 0.02803968 0.02783179 0.0273437  0.0266824 ]\n",
      "[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n",
      " b'Bicycle' b'Building' b'Window' b'Person' b'Bicycle' b'Wheel'\n",
      " b'Building' b'Building' b'Building' b'Person' b'Wheel' b'Window'\n",
      " b'Window' b'Building' b'Person' b'Van' b'Person' b'Bicycle wheel'\n",
      " b'Person' b'Window' b'Window' b'Building' b'Window' b'Window' b'Man'\n",
      " b'Person' b'Woman' b'Person' b'Clothing' b'Bicycle wheel' b'Window'\n",
      " b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing' b'Window'\n",
      " b'Bicycle' b'Land vehicle' b'House' b'House' b'Man' b'Window' b'Clothing'\n",
      " b'Window' b'Footwear' b'Person' b'Man' b'Man' b'House' b'Building'\n",
      " b'Person' b'Clothing' b'Window' b'Person' b'Man' b'Person' b'Furniture'\n",
      " b'Jeans' b'Person' b'Person' b'Person' b'Land vehicle' b'Window' b'House'\n",
      " b'Woman' b'Man' b'Window' b'Person' b'Person' b'Clothing' b'Man' b'Man'\n",
      " b'Window' b'Car' b'Person' b'Man' b'Chair' b'Car' b'House' b'Window'\n",
      " b'Tire' b'Clothing' b'Window' b'Clothing' b'Land vehicle' b'Window'\n",
      " b'Window' b'Man' b'Van' b'Bus' b'Clothing' b'Car']\n",
      "[[5.1279444e-01 5.2927095e-01 6.0166234e-01 5.5209446e-01]\n",
      " [5.1974595e-01 6.0150713e-01 6.4612412e-01 6.3468289e-01]\n",
      " [5.0574601e-01 5.0044078e-01 6.0134917e-01 5.2308965e-01]\n",
      " [4.8630881e-01 4.1276225e-01 6.7855030e-01 4.5990556e-01]\n",
      " [8.1519085e-01 9.5611835e-01 8.4270173e-01 9.8714465e-01]\n",
      " [4.9546653e-01 9.2353427e-01 8.3563489e-01 9.9905688e-01]\n",
      " [1.1098481e-02 1.1911938e-02 7.3975062e-01 4.2490727e-01]\n",
      " [5.7782602e-01 3.6645323e-01 7.1280569e-01 4.8333821e-01]\n",
      " [7.7493519e-02 4.1305405e-01 5.7945883e-01 5.6030929e-01]\n",
      " [0.0000000e+00 1.1929257e-01 2.2389720e-01 1.8394907e-01]\n",
      " [5.1406974e-01 7.4809784e-01 5.9196222e-01 7.6656920e-01]\n",
      " [5.7077789e-01 3.6182037e-01 7.0732838e-01 4.2966682e-01]\n",
      " [6.3209414e-01 3.5986990e-01 7.0384169e-01 4.1181558e-01]\n",
      " [1.5908560e-02 6.8496162e-01 5.5938882e-01 8.1114680e-01]\n",
      " [0.0000000e+00 7.9710931e-01 6.7373604e-01 1.0000000e+00]\n",
      " [0.0000000e+00 2.1702689e-01 6.5097302e-01 4.3200091e-01]\n",
      " [5.0037271e-01 3.7700447e-01 6.3335055e-01 4.1451439e-01]\n",
      " [6.4033997e-01 4.4502342e-01 7.0303476e-01 4.8345751e-01]\n",
      " [1.9440461e-03 0.0000000e+00 1.3933197e-01 2.6288422e-02]\n",
      " [2.5518609e-03 9.6662545e-01 1.5375260e-01 1.0000000e+00]\n",
      " [1.4154816e-03 1.4105014e-03 7.6484835e-01 2.6935196e-01]\n",
      " [5.0490111e-01 3.6078489e-01 6.3766336e-01 3.8548014e-01]\n",
      " [4.8338380e-01 6.1948413e-01 5.6265801e-01 6.6157210e-01]\n",
      " [4.9820146e-01 3.6461410e-01 6.6115749e-01 4.0489641e-01]\n",
      " [6.3122934e-01 3.6032286e-01 7.0414704e-01 4.1149941e-01]\n",
      " [5.2180678e-01 5.7769483e-01 5.8761311e-01 6.0071778e-01]\n",
      " [2.1960373e-01 3.4873888e-01 3.3825552e-01 3.7706766e-01]\n",
      " [1.2482674e-01 2.5092393e-01 2.7991474e-01 2.8162587e-01]\n",
      " [2.5731847e-01 5.6749362e-01 5.3091002e-01 6.8787658e-01]\n",
      " [4.2175353e-02 8.7476528e-01 2.5286341e-01 9.1304618e-01]\n",
      " [1.5640162e-01 4.4336551e-01 2.2223385e-01 4.7578454e-01]\n",
      " [5.0199443e-01 9.2146748e-01 8.3636171e-01 1.0000000e+00]\n",
      " [5.2367359e-01 5.7034701e-01 5.8450615e-01 5.9160703e-01]\n",
      " [5.1916909e-01 5.9996599e-01 6.4633018e-01 6.3409472e-01]\n",
      " [5.1315480e-01 6.7922854e-01 5.5098128e-01 6.9254810e-01]\n",
      " [5.2434456e-01 9.2494547e-01 8.1052822e-01 9.9797946e-01]\n",
      " [6.3806325e-01 4.4279733e-01 7.0172906e-01 4.8413196e-01]\n",
      " [3.4105532e-02 3.5565761e-01 1.6230491e-01 3.7490875e-01]\n",
      " [4.8809028e-01 4.5336694e-01 6.2225717e-01 4.7966492e-01]\n",
      " [9.6650445e-04 3.0770737e-01 1.0651586e-01 3.3207032e-01]\n",
      " [4.8297009e-01 6.1979169e-01 5.6477898e-01 6.6065264e-01]\n",
      " [5.8239114e-01 3.6492339e-01 7.1389163e-01 4.8468533e-01]\n",
      " [5.2379000e-01 7.4929273e-01 5.8547032e-01 7.6531148e-01]\n",
      " [3.5146424e-01 9.7486883e-01 5.5304372e-01 9.9888712e-01]\n",
      " [6.0907698e-01 4.2683351e-01 7.0519632e-01 4.8710752e-01]\n",
      " [5.6925476e-01 3.5978302e-01 7.0856631e-01 4.2843872e-01]\n",
      " [0.0000000e+00 8.1118721e-01 6.9358289e-01 9.9325359e-01]\n",
      " [1.0429459e-02 2.2946903e-02 7.2731262e-01 4.2228761e-01]\n",
      " [4.8463222e-01 4.1069776e-01 6.9474280e-01 4.6313995e-01]\n",
      " [8.1154458e-02 3.8477594e-01 2.0795214e-01 4.1175538e-01]\n",
      " [5.3856725e-01 6.0358500e-01 6.3474077e-01 6.3447654e-01]\n",
      " [0.0000000e+00 1.2407588e-02 1.4029649e-01 2.4734119e-02]\n",
      " [6.2977999e-01 6.1488342e-01 6.4490795e-01 6.2533504e-01]\n",
      " [5.0284290e-01 3.8242069e-01 5.9601623e-01 4.1271871e-01]\n",
      " [5.1468140e-01 7.4787104e-01 5.9194773e-01 7.6678252e-01]\n",
      " [5.0643331e-01 5.0040275e-01 6.0071695e-01 5.2331966e-01]\n",
      " [0.0000000e+00 2.1112862e-01 6.5082592e-01 4.3438426e-01]\n",
      " [0.0000000e+00 7.0632058e-01 6.1716139e-01 8.6594033e-01]\n",
      " [4.8929805e-01 4.5427489e-01 5.7262009e-01 4.7639754e-01]\n",
      " [5.0920737e-01 4.1626489e-01 6.6901666e-01 4.5957717e-01]\n",
      " [4.6780333e-03 8.0310708e-01 1.5958224e-01 8.4036523e-01]\n",
      " [5.2617568e-01 5.6837583e-01 5.7943624e-01 5.8280307e-01]\n",
      " [5.0284761e-01 3.7398592e-01 6.4712596e-01 4.1297260e-01]\n",
      " [4.8591751e-01 4.4443721e-01 6.2469023e-01 4.7351980e-01]\n",
      " [5.7416862e-01 2.6725137e-01 6.5776157e-01 3.2031402e-01]\n",
      " [6.7198229e-01 9.4031775e-01 8.2117712e-01 9.8921400e-01]\n",
      " [5.2410477e-01 5.6155598e-01 5.7834703e-01 5.8050251e-01]\n",
      " [5.1758969e-01 7.5722051e-01 5.8831400e-01 7.7154577e-01]\n",
      " [5.2332854e-01 5.5781382e-01 5.7902890e-01 5.7355350e-01]\n",
      " [6.1236006e-01 4.2740157e-01 7.0609623e-01 4.8830026e-01]\n",
      " [0.0000000e+00 2.4423711e-01 6.0888764e-02 2.9377386e-01]\n",
      " [1.5484416e-02 1.9419279e-03 7.4516338e-01 2.5933653e-01]\n",
      " [4.9326640e-01 9.2395955e-01 8.3691329e-01 9.9770677e-01]\n",
      " [5.0529295e-01 3.6016643e-01 6.4336234e-01 3.9143851e-01]\n",
      " [8.4342277e-03 2.4212143e-01 4.9744956e-02 2.8314558e-01]\n",
      " [5.2210915e-01 5.3608805e-01 5.9767485e-01 5.5313319e-01]\n",
      " [5.1312602e-01 5.2381009e-01 6.0054040e-01 5.4296505e-01]\n",
      " [5.1831567e-01 5.0345343e-01 5.9754533e-01 5.2275288e-01]\n",
      " [5.2045572e-01 6.0093164e-01 6.4599109e-01 6.3436383e-01]\n",
      " [5.1316833e-01 6.7925388e-01 5.5048615e-01 6.9244295e-01]\n",
      " [4.2972320e-01 8.2874358e-01 5.9004873e-01 8.6437541e-01]\n",
      " [5.2659333e-01 6.2719077e-01 5.6328988e-01 6.5378505e-01]\n",
      " [5.0478113e-01 3.8941064e-01 6.1523122e-01 4.1995159e-01]\n",
      " [5.0132489e-01 3.6423627e-01 6.5975285e-01 4.0371996e-01]\n",
      " [5.7311028e-01 2.6673275e-01 6.6622359e-01 3.1864995e-01]\n",
      " [5.1510334e-01 6.2409180e-01 5.6383228e-01 6.5803182e-01]\n",
      " [8.3203174e-02 4.0756792e-01 5.8434409e-01 5.5831045e-01]\n",
      " [2.8820190e-01 4.6255547e-04 4.1427985e-01 3.6707677e-02]\n",
      " [6.2713277e-01 3.6099508e-01 7.0596069e-01 4.0978041e-01]\n",
      " [4.9715948e-01 4.5521107e-01 5.8427131e-01 4.7787207e-01]\n",
      " [1.1719415e-02 3.0807254e-01 9.7320050e-02 3.2507548e-01]\n",
      " [5.1589394e-01 3.8009039e-01 5.9697241e-01 4.1176715e-01]\n",
      " [5.1242900e-01 6.2364930e-01 5.6243664e-01 6.5768224e-01]\n",
      " [4.0077379e-01 8.8497430e-01 5.8165658e-01 9.3913019e-01]\n",
      " [0.0000000e+00 9.9475905e-03 1.3625403e-01 3.1597443e-02]\n",
      " [5.1390564e-01 5.2950239e-01 6.0205597e-01 5.5237609e-01]\n",
      " [5.1069152e-01 6.2403965e-01 5.6341004e-01 6.5817988e-01]\n",
      " [4.8037997e-01 6.2032783e-01 5.6528413e-01 6.6012347e-01]\n",
      " [5.3840739e-01 9.2802429e-01 7.1361727e-01 9.9945271e-01]\n",
      " [4.8633784e-01 6.2024736e-01 5.6352872e-01 6.6021776e-01]]\n"
     ]
    }
   ],
   "source": [
    "# runs the object detection model and prints information about the objects found\n",
    "run_detector(detector, downloaded_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
